# -*- coding: utf-8 -*-
"""CraigslistFeedbackAnalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1psH2qHxq3AhPz1S-LDIbH7bFqKnCIBRN
"""

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import  WordNetLemmatizer
from nltk import word_tokenize, pos_tag
import pandas as pd
import numpy as np
import sklearn.metrics as metrics
from sklearn.metrics import classification_report
#!pip install lda_classification
from lda_classification.model import TomotopyLDAVectorizer
import spacy
from sklearn.ensemble import VotingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

df = pd.read_excel('Final Data.xlsx',sheet_name=2)

drop_lst=[]
for index, row in df.iterrows():
    if not len(row[0])>100:
        drop_lst.append(index)

df_new = df.drop(df.index[drop_lst],axis=0)
df_new.shape

lst=df_new.Comments.tolist()
target=df_new.Label.to_list()

# word_tokenizer for the entire review list
import nltk
nltk.download('punkt')
tokens = [word_tokenize(i) for i in lst]
len(tokens)

# lemmatization
wn = WordNetLemmatizer()
nltk.download('wordnet')
lemmatized_tokens = [[wn.lemmatize(token.lower()) for token in i if token.isalpha()] for i in tokens]

#stop words
from nltk.corpus import stopwords
nltk.download('stopwords')
lst2 = [' '.join([token for token in i if not token in stopwords.words('english')]) for i in lemmatized_tokens]

#Tfidf vectorizer
from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer
cv=TfidfVectorizer(ngram_range=(1,2),min_df=2)
arr=cv.fit_transform(lst2)
arr.shape

# split data
import random
from sklearn.model_selection import train_test_split
random.seed(114)

# evaluation
target_names = ['class 0', 'class 1', 'class 2','class 3']

X_train, X_test, y_train, y_test = train_test_split(arr, target, test_size=0.2, shuffle=True,stratify=target)

## Naive Bayes models

from sklearn.naive_bayes import ComplementNB
cnb=ComplementNB()
cnb.fit(X_train,y_train)

predicted = cnb.predict(X_test)
accuracy_score = metrics.accuracy_score(y_test, predicted)
print('Complement Naive Bayes Model Accuracy')
print(str('{:4.2f}'.format(accuracy_score*100))+'%')
print(classification_report(y_test, predicted, target_names=target_names))

## Logistic Regression
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC

LM=LogisticRegression()
LM.fit(X_train, y_train)

y_pred=LM.predict(X_test)
accuracy_score_lsvc = metrics.accuracy_score(y_test,y_pred)
print('Logistic Regression Model Accuracy')
print(str('{:4.2f}'.format(accuracy_score_lsvc*100))+'%')
print(classification_report(y_test, y_pred, target_names=target_names))

## SVC
LSVC = LinearSVC()
LSVC.fit(X_train, y_train)

y_pred=LSVC.predict(X_test)
accuracy_score_lsvc = metrics.accuracy_score(y_test,y_pred)
print('SVC Model Accuracy')
print(str('{:4.2f}'.format(accuracy_score_lsvc*100))+'%')
print(classification_report(y_test, y_pred, target_names=target_names))

## Stochastic Gradient Descent (SGD)
from sklearn.linear_model import SGDClassifier
SGDC = SGDClassifier()
SGDC.fit(X_train, y_train)

y_pred=SGDC.predict(X_test)
accuracy_score_sgdc = metrics.accuracy_score(y_test, y_pred)
print('SGD Model Accuracy')
print(str('{:4.2f}'.format(accuracy_score_sgdc*100))+'%')
print(classification_report(y_test, y_pred, target_names=target_names))

## Deep learning model
from sklearn.neural_network import MLPClassifier
DLmodel = MLPClassifier (hidden_layer_sizes = (8))

DLmodel.fit(X_train,y_train)
y_pred_DL = DLmodel.predict(X_test)

from sklearn import metrics
acc_DL = metrics.accuracy_score(y_test, y_pred_DL)
print('Deep Learning Model Accuracy')
print(str('{:4.2f}'.format(acc_DL*100))+'%')
print(classification_report(y_test, y_pred_DL, target_names=target_names))

## Tree based model

DTmodel = DecisionTreeClassifier()
RFmodel = RandomForestClassifier(n_estimators = 5000, max_depth = 14, bootstrap = True, random_state = 0)

DTmodel.fit(X_train, y_train)
y_pred_DT = DTmodel.predict(X_test)

RFmodel.fit(X_train, y_train)
y_pred_RF = RFmodel.predict(X_test)

acc_DT = metrics.accuracy_score(y_test, y_pred_DT)
print('Decision Tree Model Accuracy')
print(str('{:4.2f}'.format(acc_DT*100))+'%')
print(classification_report(y_test, y_pred_DT, target_names=target_names))

acc_RF = metrics.accuracy_score(y_test, y_pred_RF)
print('Random Forest Model Accuracy')
print(str('{:4.2f}'.format(acc_RF*100))+'%')
print(classification_report(y_test, y_pred_RF, target_names=target_names))

# LGBM
import lightgbm

lgbm=lightgbm.LGBMClassifier()
lgbm.fit(X_train,y_train)

y_pred=lgbm.predict(X_test)
accuracy_score_lsvc = metrics.accuracy_score(y_test,y_pred)
print(str('{:4.2f}'.format(accuracy_score_lsvc*100))+'%')
print(classification_report(y_test, y_pred, target_names=target_names))

import numpy as np
from sklearn.model_selection import RandomizedSearchCV

#Define the parameters
parameters = {'n_estimators': [50,65,80,100,115,130,150],'num_leaves':[20,40,60,80,100], 'min_child_samples':[5,10,15],'max_depth': [1,5,10,15,20],
             'learning_rate':[0.05,0.1,0.2],'reg_alpha':[0,0.01,0.03]}

#Define the scoring
clf=RandomizedSearchCV(lgbm,parameters,scoring='accuracy')
clf.fit(X=X_train, y=y_train)
print(clf.best_params_)
predicted=clf.predict(X_test)

# Multinomial NB
from sklearn.naive_bayes import MultinomialNB

mnb = MultinomialNB()
mnb.fit(X_train,y_train)
predicted = mnb.predict(X_test)
accuracy_score = metrics.accuracy_score(y_test, predicted)
print('Mulinomial Naive Based Model Accuracy')
print(str('{:4.2f}'.format(accuracy_score*100))+'%')
print(classification_report(y_test, predicted, target_names=target_names))

# Bernoulli NB
from sklearn.naive_bayes import BernoulliNB
bnb = BernoulliNB()
bnb.fit(X_train,y_train)
predicted = bnb.predict(X_test)
accuracy_score = metrics.accuracy_score(y_test, predicted)
print('Bernoulli Naive Based Model Accuracy')
print(str('{:4.2f}'.format(accuracy_score*100))+'%')
print(classification_report(y_test, predicted, target_names=target_names))

X=arr
y=target

model=[SGDC, LSVC, mnb, cnb, bnb, lgbm, DTmodel, clf, DLmodel, LM]
cv_score=[]
for i in model:
    from sklearn.model_selection import cross_val_score
    scores = cross_val_score(i, X, y, cv=5)
    cv_score.append(scores)
    
mean_score=[]
std_score=[]
for i in range(len(cv_score)):
    mean_score.append(cv_score[i].mean())
    std_score.append(cv_score[i].std())

pd.DataFrame({'mean_score':mean_score,'std_dev':std_score},index=model)

## Final ensemble model
from sklearn.ensemble import VotingClassifier
clf4 = VotingClassifier(estimators = [('sgd',SGDC), ('svc', LSVC),('fit_lgbm',clf)], voting='hard') 

# train the ensemble classifier
clf4.fit(X_train, y_train)

scores = cross_val_score(clf4, X, y, cv=5)
print(scores.mean())

accuracy_score_lsvc = metrics.accuracy_score(y_test,clf4.predict(X_test))
print(str('{:4.2f}'.format(accuracy_score_lsvc*100))+'%')
print(classification_report(y_test, clf4.predict(X_test), target_names=target_names))

"""# LIME, HDP and LDA"""

#prediction using LDA

from sklearn.decomposition import LatentDirichletAllocation

lda= LatentDirichletAllocation(n_components=8,random_state=0)
output = lda.fit_transform(arr)

#topicnames = ["topic" + str(i) for i in range(1000)]
#docnames = ["Doc" + str(i) for i in range(len(df.index))]

#top_doc = pd.DataFrame(output, columns=topicnames, index=docnames)
#top_doc

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from sklearn.metrics import classification_report,roc_auc_score

X_train, X_val, y_train, y_val = train_test_split(output, target, test_size=0.2, shuffle=True)

# Scale Data
scaler = StandardScaler()
X_train_scale = scaler.fit_transform(X_train)
X_val_scale = scaler.transform(X_val)

from sklearn.metrics import f1_score
# Logisitic Regression
lr = LogisticRegression(
    class_weight= 'balanced',
    solver='newton-cg',
    fit_intercept=True
).fit(X_train_scale, y_train)

y_pred = lr.predict(X_val_scale)
accuracy_score_lr = metrics.accuracy_score(y_test, y_pred)
print('accuracy_score_lr = '+str('{:4.2f}'.format(accuracy_score_lr*100))+'%')
print(f1_score(y_test, y_pred, average='weighted'))
print(classification_report(y_test, y_pred, target_names=target_names))

# Logistic Regression SGD
sgd = SGDClassifier(
    max_iter=1000,
    tol=1e-3,
    loss='log',
    class_weight='balanced'
).fit(X_train_scale, y_train)

y_pred = sgd.predict(X_val_scale)
accuracy_score_sgd = metrics.accuracy_score(y_test, y_pred)
print('accuracy_score_sgd = '+str('{:4.2f}'.format(accuracy_score_sgd*100))+'%')
print(f1_score(y_test, y_pred, average='weighted'))
print(classification_report(y_test, y_pred, target_names=target_names))

class_names = {0: 'Categories', 1:'Cities',2:'Bugs&Outages',3:'Flagged'}
##LIME Explainability

from sklearn.pipeline import make_pipeline
# !pip install lime
import lime
from lime import lime_text
from lime.lime_text import LimeTextExplainer

c = make_pipeline(cv, clf)
explainer = LimeTextExplainer(class_names=class_names)

idx = 11
exp = explainer.explain_instance(lst[idx], c.predict_proba, num_features=6,top_labels=2)
print('True label')
print(target[idx])
exp.show_in_notebook(text=True)

df_bugs=df_new[df.Label==2]
lst2=df_bugs.Comments.tolist()
target2=df_bugs.Label.to_list()

# word_tokenizer for the entire review list
tokens = [word_tokenize(i) for i in lst2]
len(tokens)

# lemmatization
wn = WordNetLemmatizer()
lemmatized_tokens = [[wn.lemmatize(token.lower()) for token in i if token.isalpha()] for i in tokens]

#stop words
from nltk.corpus import stopwords
lst2 = [' '.join([token for token in i if not token in stopwords.words('english')]) for i in lemmatized_tokens]

#Tfidf vectorizer
from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer
cv=CountVectorizer(ngram_range=(1,2),min_df=2)
arr2=cv.fit_transform(lst2)
arr2.shape

## HDP to use optimal topics

from sklearn.pipeline import Pipeline
from tomotopy import HDPModel
min_df=2
rm_top=5
workers = 0
hdp_model = HDPModel(min_df=min_df, rm_top=rm_top)
hdp_model.optim_interval = 5
for d in lst2:
    hdp_model.add_doc(d)
hdp_model.burn_in = 100
hdp_model.train(0, workers=workers)
for i in range(0, 1000, 10):
    hdp_model.train(10, workers=workers)
    print('Iteration: {}\tLog-likelihood: {}\tNum. of topics: {}'.format(i, hdp_model.ll_per_word, hdp_model.live_k))

num_of_topics = hdp_model.live_k

from sklearn.decomposition import LatentDirichletAllocation

lda= LatentDirichletAllocation(n_components=num_of_topics,random_state=0)
output = lda.fit_transform(arr2)

topicnames = ["topic" + str(i) for i in range(2)]
docnames = ["Doc" + str(i) for i in range(len(df_bugs.index))]

top_doc = pd.DataFrame(output, columns=topicnames, index=docnames)
top_doc

#!pip install pyLDAvis==3.2.1
from __future__ import print_function
import pyLDAvis
import pyLDAvis.sklearn
pyLDAvis.enable_notebook()

panel = pyLDAvis.sklearn.prepare(lda, arr2, cv, mds='tsne')
panel